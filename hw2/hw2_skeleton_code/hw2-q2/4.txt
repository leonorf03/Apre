Using small kernels in convolutional layers instead of a kernel of width x height kernels offers significant advantages in both efficiency and performance. Smaller kernels are better at capturing local patterns, such as edges, textures, and fine details. By stacking multiple layers with small kernels, the network achieves the same receptive field as a single large kernel but with fewer parameters and nonlinear activations in between. This increases the network's representational power while reducing the risk of overfitting.

Pooling layers are crucial in CNNs as they  reduce the spatial dimensions of feature maps which offers several advantages. First, they perform dimensionality reduction, lowering computational costs and reducing the risk of overfitting by minimizing the number of parameters in the model. Second, pooling layers enhance translation invariance, ensuring that the network can detect features regardless of their position in the image. Finally, pooling aids in feature selectionâ€”max pooling for example highlights the most prominent features, while average pooling preserves more detailed information. These benefits contribute to the efficiency and robustness of the network.

Together, smaller kernels and pooling layers improve the robustness and generalization of convolutional neural networks.